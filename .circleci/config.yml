version: 2.1
jobs:
  build-and-scrape:
    working_directory: ~/project/RPScraper
    docker:
      - image: circleci/python:3.7.2
    steps:
      - checkout
      - run:
          command: |
            cd RPScraper
            chmod u+x scripts/build_and_scrape.sh
            ./scripts/build_and_scrape.sh
  upload-data:
    working_directory: ~/project
    docker:
      - image: circleci/python:3.7.2
    steps:
      - checkout
      - run:
          command: |
            chmod u+x RPScraper/scripts/upload_data.sh
            ./RPScraper/scripts/upload_data.sh
  run-crawler:
    working_directory: ~/project
    docker:
      - image: circleci/python:3.7.2
    steps:
      - checkout
      - run:
          command: |
            python RPScraper/src/run_glue_crawler.py

orbs:
  aws-cli: circleci/aws-cli@1.0.0
workflows:
  version: 2.1
  daily-update:
    jobs:
      - build-and-scrape
      - upload-data:
          requires:
            - build-and-scrape
          context: aws
#    triggers:
#      - schedule:
#          cron: "0 0 * * *"
#          filters:
#            branches:
#              only:
#                - master
  update-and-crawl:
    jobs:
      - build-and-scrape
      - upload-data:
          requires:
            - build-and-scrape
          context: aws
      - run-crawler:
          requires:
            - upload-data
          context: aws
          timeout: 1500